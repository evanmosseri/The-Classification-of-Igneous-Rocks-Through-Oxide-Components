{
 "metadata": {
  "name": "",
  "signature": "sha256:17f5d490bdda6157584e3bad7e7856d6f1190b24b97ee83fae67fb730c30752f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy as st\n",
      "import csv\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import rocksep_utils as utl\n",
      "from rocksep_utils import *\n",
      "import time\n",
      "import mpld3\n",
      "from StringIO import StringIO\n",
      "from pydot import graph_from_dot_data\n",
      "\n",
      "# from sklearn.ensemble import BaggingClassifier\n",
      "from sklearn import cross_validation\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.qda import QDA\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.lda import LDA\n",
      "import sklearn.tree as tree\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "dataURL = \"peridotites_clean_complete.csv\"\n",
      "\n",
      "rock_types={'DUNITE' :1,'HARZBURGITE':2, 'LHERZOLITE':3, 'WEHRLITE':4}\n",
      "\n",
      "pd_data = pd.read_csv(dataURL)\n",
      "chemicals = pd_data.keys()[1:].tolist()\n",
      "print chemicals\n",
      "rock_names = np.unique(pd_data[pd_data.keys()[0]])\n",
      "\n",
      "# random_data = pd_data.values\n",
      "# np.random.shuffle(random_data)\n",
      "# np.save(random_data,\"random_data.npy\")\n",
      "random_data = np.load(\"random_data.npy\")\n",
      "\n",
      "raw_data = random_data[:,1:]\n",
      "labels = random_data[:,0]\n",
      "\n",
      "\n",
      "\n",
      "def numbered_labels(labels,key):\n",
      "    return [key[labels[i]] for i in range(len(labels))]\n",
      "nlabels =  numbered_labels(labels,rock_types)\n",
      "\n",
      "def create_train_test(feature_mat,ylabels):\n",
      "    train, test = iter(StratifiedKFold(ylabels, n_fold=3)).next()\n",
      "    print \"n_training_examples: %d\" % len(train)\n",
      "    print \"n_testing_examples: %d\" % len(test)\n",
      "    feature_train, feature_test = feature_mat[train], feature_mat[test]\n",
      "    ylabels_train, ylabels_test = ylabels[train], ylabels[test]\n",
      "    X,y = feature_train,ylabels_train\n",
      "    X_test,y_test = feature_test,ylabels_test\n",
      "    return X,y,X_test,y_test\n",
      "\n",
      "def nearest_neighbors(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    neigh = KNeighborsClassifier(n_neighbors=n)\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"Nearest Neighbors\"\n",
      "\n",
      "def random_forest(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    neigh = RandomForestClassifier(n_estimators=n)\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"Random Forest\"\n",
      "\n",
      "def naive_base(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    neigh = GaussianNB()\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"Naive Base\"\n",
      "\n",
      "def qda(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    neigh = QDA(priors=None, reg_param=0.0)\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"QDA\"\n",
      "\n",
      "def svc(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    # neigh = SVC()\n",
      "    neigh = SVC(kernel=\"linear\", C=0.025)\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"SVC\"\n",
      "\n",
      "def lda(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    neigh = LDA(n_components=None, priors=None)\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"LDA\"\n",
      "\n",
      "def qda(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    neigh = QDA()\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"QDA\"\n",
      "\n",
      "\n",
      "def ada(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    neigh = AdaBoostClassifier()\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"ADA Boost\"  \n",
      "\n",
      "def decision_tree(data,labels,n):\n",
      "    # train_data = data[0:int(len(data)/2)]\n",
      "    # test_data = data[int(len(data)/2):]\n",
      "    # train_labels = labels[0:int(len(labels)/2)]\n",
      "    # test_labels = labels[int(len(labels)/2):]\n",
      "    train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "    neigh = DecisionTreeClassifier(max_depth=5)\n",
      "    neigh.fit(train_data, train_labels)\n",
      "    y_pred = neigh.predict(test_data)\n",
      "    pure_accuracy_rate = len([y_pred[x] for x in range(len(y_pred)) if y_pred[x] == test_labels[x]])/float(len(test_labels))\n",
      "    report = classification_report(y_pred, test_labels, target_names=rock_names)\n",
      "    cm = confusion_matrix(test_labels, y_pred)\n",
      "    return pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,\"Decision Tree\" \n",
      "\n",
      "\n",
      "def get_lineage(tree, feature_names):\n",
      "     left      = tree.tree_.children_left\n",
      "     right     = tree.tree_.children_right\n",
      "     threshold = tree.tree_.threshold\n",
      "     features  = [feature_names[i] for i in tree.tree_.feature]\n",
      "\n",
      "     # get ids of child nodes\n",
      "     idx = np.argwhere(left == -1)[:,0]     \n",
      "\n",
      "     def recurse(left, right, child, lineage=None):          \n",
      "          if lineage is None:\n",
      "               lineage = [child]\n",
      "          if child in left:\n",
      "               parent = np.where(left == child)[0].item()\n",
      "               split = 'l'\n",
      "          else:\n",
      "               parent = np.where(right == child)[0].item()\n",
      "               split = 'r'\n",
      "\n",
      "          lineage.append((parent, split, threshold[parent], features[parent]))\n",
      "\n",
      "          if parent == 0:\n",
      "               lineage.reverse()\n",
      "               return lineage\n",
      "          else:\n",
      "               return recurse(left, right, parent, lineage)\n",
      "\n",
      "     for child in idx:\n",
      "          for node in recurse(left, right, child):\n",
      "               print node\n",
      "\n",
      "\n",
      "def plotAnalysis(test_data,test_labels,y_pred,cmap,plot_vars,type,title,accuracy,plot=True,cache=False,save=False,analysis_type=\"\"):\n",
      "    fig = plt.figure()\n",
      "    ax = fig.add_subplot(111, projection='3d')\n",
      "#     print chemicals.index(plot_vars[1]),plot_vars[0]\n",
      "    x1,y1,z1 = [test_data[:,chemicals.index(x)] for x in plot_vars]\n",
      "#     hit_shapes = {True:\"*\",False:\"o\"}\n",
      "\n",
      "#     hit_mat = [y_pred[i] == test_labels[i] for i in range(len(test_labels))]\n",
      "#     hit_shapes_mat = [hit_shapes[i] for i in hit_mat]\n",
      "#     rock_colors = [cmap[x] for x in test_labels]\n",
      "\n",
      "#     for i in range(len(hit_shapes_mat)):\n",
      "#         ax.scatter(x1[i], y1[i], zs=z1[i], c=rock_colors[i], marker=hit_shapes_mat[i],s=50)\n",
      "\n",
      "#     proxy_labels = [matplotlib.lines.Line2D([0],[0], linestyle=\"none\", c='black', marker = 'o'), matplotlib.lines.Line2D([0],[0], linestyle=\"none\", c='black', marker = '*')]\n",
      "#     for i in rock_types.values():\n",
      "#         proxy_labels.append(matplotlib.lines.Line2D([0],[0], linestyle=\"none\", c=cmap[i], marker = 'o'))\n",
      "#     ax.legend(proxy_labels, ['Incorrectly Classified', 'Correctly Classified']+rock_types.keys(), numpoints = 1,prop={'size':6},bbox_to_anchor=(1.1, .1))\n",
      "#     ax.set_xlabel(plot_vars[0])\n",
      "#     ax.set_ylabel(plot_vars[1])\n",
      "#     ax.set_zlabel(plot_vars[2])\n",
      "#     ax.set_title(analysis_type+\": \"+title+\":\\n Overall Accuracy: \"+\"%.1f%%\" % accuracy)\n",
      "#     if plot == True:\n",
      "#         plt.show()\n",
      "#     if cache == True:\n",
      "#         plt.savefig(\"./matplotlib_cache/{}_figure{}.png\".format(analysis_type,time.time()))\n",
      "#     if save == True:\n",
      "#         plt.savefig(\"./matplotlib_save/new/{}_figure{}.png\".format(analysis_type,time.time())) \n",
      "#     return fig\n",
      "# def exportDecisionTree(neigh):\n",
      "#     out = StringIO()\n",
      "#     out = tree.export_graphviz(neigh, out_file=out)\n",
      "#     graph_from_dot_data(out.getvalue()).write_pdf(\"somefile.pdf\")\n",
      "#     out.getvalue().write_pdf(\"somefile.pdf\")\n",
      "#     return out\n",
      "def show_confusion_matrix(cm,plot,cache,save,a_type=\"\",accuracy=None):\n",
      "    fig = plt.figure()\n",
      "    ax0 = fig.add_subplot(1,1,1)\n",
      "    def normalize_mat(cm):\n",
      "        cm = cm.tolist()\n",
      "        for i in range(len(cm)):\n",
      "            rsum = np.sum(cm[i])\n",
      "            for x in range(len(cm[0])):\n",
      "                cm[i][x] = float(cm[i][x])/rsum\n",
      "        return np.array(cm)\n",
      "    im = ax0.imshow(normalize_mat(cm), interpolation='nearest',cmap='Reds')\n",
      "    plt.xticks(np.arange(0,4), [\"DUNITE\",\"HARZBURGITE\",\"LHERZOLITE\",\"WEHRLITE\"])\n",
      "    plt.yticks(np.arange(0,4), [\"DUNITE\",\"HARZBURGITE\",\"LHERZOLITE\",\"WEHRLITE\"])\n",
      "    plt.colorbar(im)\n",
      "    ax0.set_title(\"{} Confusion Matrix\\n {} accuracy\".format(a_type,accuracy))\n",
      "    if plot == True:\n",
      "        plt.show()\n",
      "    if cache == True:\n",
      "        plt.savefig(\"./matplotlib_cache/{}confusion_matrix{}.png\".format(a_type,time.time()))\n",
      "    if save == True:\n",
      "        plt.savefig(\"./matplotlib_save/{}confusion_matrix{}.png\".format(a_type,time.time())) \n",
      "    return fig\n",
      "def plot_algorithms(algorithms,raw_data,nlabels,plot_vars,cmap={1:\"red\",2:\"green\",3:\"blue\",4:\"orange\"},supress=False):\n",
      "    values = []\n",
      "    for i in algorithms:\n",
      "        pure_accuracy_rate,report,y_pred,test_labels,test_data,neigh,cm,analysis_type = i(raw_data,nlabels,4)\n",
      "        pure_accuracy_rate = pure_accuracy_rate*100\n",
      "#         print analysis_type+\"\\n\",\"Pure Accuracy: %.1f%%\" % (pure_accuracy_rate)+\"\\n\", report, cm\n",
      "        if not(supress):\n",
      "            fig = plotAnalysis(test_data,test_labels,y_pred,cmap,plot_vars,analysis_type,\"3 Dimensional Demonstration of Classifier Accuracy\",pure_accuracy_rate,False,False,True,i.func_name.title().replace(\"_\",\" \"))\n",
      "        show_confusion_matrix(cm,False,False,True,a_type=i.func_name.title().replace(\"_\",\" \"),accuracy=\"%.1f%%\" % (pure_accuracy_rate))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['SIO2', 'TIO2', 'AL2O3', 'CR2O3', 'FEOT', 'CAO', 'MGO', 'MNO', 'K2O', 'NA2O', 'P2O5']\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" TODO:\n",
      "- implement k-fold cross validation\n",
      "- implement percent chance system\n",
      "- try to implement boosting/bootstraping         \n",
      "\"\"\"\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import scipy as st\n",
      "import csv\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import time\n",
      "import mpld3\n",
      "from StringIO import StringIO\n",
      "from pydot import graph_from_dot_data\n",
      "\n",
      "from sklearn import cross_validation\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.metrics import confusion_matrix\n",
      "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.qda import QDA\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.lda import LDA\n",
      "import sklearn.tree as tree\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "from sklearn import cross_validation\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "\n",
      "cmap = {1:\"red\",2:\"green\",3:\"blue\",4:\"orange\"}\n",
      "plot_vars = [\"SIO2\",\"AL2O3\",\"MGO\"]\n",
      "\n",
      "algorithms = [nearest_neighbors,random_forest,naive_base,ada,decision_tree]\n",
      "\n",
      "plot_algorithms(algorithms,raw_data,nlabels,plot_vars)\n",
      "# train_data,test_data,train_labels,test_labels = cross_validation.train_test_split(data, labels, test_size=0.3, random_state=0)\n",
      "\n",
      "\n",
      "# print create_train_test(raw_data,nlabels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}